## 写以一个分布式作业的学习记录

ass4

使用`nvidia-smi`查看gpu信息

![image-20231102091405781](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20231102091405781.png)

解读如下：

https://blog.csdn.net/wumenglu1018/article/details/103057009

上图显示的显卡信息，第一行是版本信息，第二行是标题栏，第三行是具体的显卡信息。如果有多个显卡，就会有多行对应标题栏的信息。例如我上面显示了共0~4号，共5个卡。

GPU：显卡编号，从0开始。
Fan：风扇转速，在0~100%之间变动。这个速度是计算机期望的风扇转速，实际情况下如果风扇堵转，可能就不会显示具体转速值。有的设备不会返回转速，因为它不依赖风扇冷却，而是通过其他外设保持低温，比如我们实验室的服务器是常年放在空掉房间里面的。
Name：显卡名，以上都是Tesla。
Temp：显卡内部的温度，以上分别是54、49、46、50、39摄氏度。
Perf：性能状态，从P0到P12，P0性能最大，P12最小 。
Persistence-M：持续模式的状态开关，持续模式虽然耗能大，但是在新的GPU应用启动时，花费的时间更少。以上都是Off的状态。
Pwr：能耗表示。
Bus-Id：涉及GPU总线的相关信息。
Disp.A：是Display Active的意思，表示GPU的显示是否初始化。
Memory-Usage：显存的使用率。
GPU-Util：GPU的利用率。
Compute M.：计算模式。
下面的Process显示每块GPU上每个进程所使用的显存情况。
显卡占用和GPU占用是两个不一样的东西，显卡是由GPU和显卡等组成的，显卡和GPU的关系有点类似于内存和CPU的关系，两个指标的占用率不一定是互相对应的。例如跑tensorflow代码的时候，可能显存占得多，GPU占得少。



---

2023年11月2日17点19分

### cuda相关

使用指令运行cuda时，顺序要注意，不然找不到，要先生成执行文件，如下：

![image-20231102173814199](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20231102173814199.png)

然后可以通过程序查看GPU架构信息如下

~~~cpp
#include <cuda_runtime.h>
#include <iostream>

int main() {
    int deviceCount;
    cudaGetDeviceCount(&deviceCount);

    for (int i = 0; i < deviceCount; ++i) {
        cudaDeviceProp deviceProp;
        cudaGetDeviceProperties(&deviceProp, i);
        std::cout << "Device " << i << ": " << deviceProp.name << std::endl;
        std::cout << "Compute Capability: " << deviceProp.major << "." << deviceProp.minor << std::endl;
    }

    return 0;
}
~~~



运行一个cuda程序需要设置cuda编译器选项，具体指令如下：

~~~c++
//要设置CUDA编译器选项，您需要使用nvcc编译器。以下是一些常用的选项：

-arch：指定目标GPU的架构。例如，-arch=sm_60表示目标GPU的架构为Pascal。
-O：指定优化级别。例如，-O3表示最高级别的优化。
-g：生成调试信息。
-I：指定包含文件的路径。
-L：指定库文件的路径。
-l：指定要链接的库文件。
//您可以在命令行中使用这些选项，例如：

nvcc -arch=sm_60 -O3 -g -I/path/to/include -L/path/to/lib -lmylib mycode.cu -o myexe
//这将编译名为“mycode.cu”的CUDA源文件，并链接名为“mylib”的库文件，生成名为“myexe”的可执行文件。请注意，选项的顺序很重要，因为它们会影响编译器的行为。
~~~



使用自己的3090时，架构要这样设置

> 如果您的目标设备是NVIDIA GeForce RTX 3090，其计算能力为8.6（Ampere架构），您可以使用以下命令来设置CUDA编译器选项：
>
> ```
> nvcc -arch=sm_86 code.cu -o output
> ```
>
> 这将使用nvcc编译器将名为`code.cu`的CUDA源文件编译为可执行文件，并将其命名为`output`。通过将`-arch`选项设置为`sm_86`，您指定了目标GPU的架构为Ampere（计算能力8.6）。
>
> 请确保将`code.cu`替换为您实际的CUDA源文件名，并将`output`替换为您希望生成的可执行文件的名称。

猜测这里的数字应该就是算力数字拼接作为架构号



---

2023年11月2日22点04分

一个很严肃的问题，在写一个gpu上的程序的时候，一直报错说什么找不到内容，应输入表达式之类的，问了gpt，找了半天没解决

**后来看了一下是文件类型错了，这样的文件应该是.cu结尾的，不是.cpp结尾的** 解决过程就是让gpt帮我写一个测试程序的时候猛然看到了

然后使用了.cu类型后有一个新的错
`找不到 __cudaPushCallConfiguration 声明。CUDA 工具包安装可能已损坏。C/C++(3118)`

解决方案：

> 设置`c_cpp_properties.json`中编译器选项，把默认的`gcc`改成`nvcc`即可解决问题。 

当然需要找到自己nvcc位置`whereis nvcc`，然后自己的文件配置修改：

~~~cpp
{
    "configurations": [
        {
            "name": "Linux",
            "includePath": [
                "${workspaceFolder}/**",
                // settings
                "/usr/include/**",
                "/usr/local/**",
                "/usr/include/x86_64-linux-gnu/mpich"
            ],
            "defines": [],
            "compilerPath": "/usr/bin/gcc",
            "compilerPath": "/usr/local/cuda-11.2/bin/nvcc",  // 加上这个
            "cStandard": "c17",
            "cppStandard": "gnu++14",
            "intelliSenseMode": "linux-gcc-x64"
        }
    ],
    "version": 4
}
~~~



---

2023年11月9日10点25分

## 文章阅读

要能够把相应模型的缺点，不足之处做好记录，可以细致到模型内部，这样方便在后期总结的时候表述。

最好直接记录，定期总结。



2023年11月10日09点27分

### word中方框打勾方法

1. 将光标定位于需要打钩的地方，选择【插入】→【符号】→【其他符号】，在弹出的符号栏里，字体一定要改成【Windings2】，然后在符号栏便可以找到现成的打钩样式，点击插入，再关闭即可
2. 把光标定位于需要打钩的地方，输入大写字母R，选中字母R，鼠标右键，在菜单栏中选择字体，在西文字体栏目中，将字体改为【Windings2】，点击下方确定按钮，这时，R就变成了我们需要的打钩样式了**提示：如果要打叉，把R改成T即可**
3. 将光标定位于要打钩的地方，输入2611，选中2611，同时按住键盘的Alt+X键，此时，2611就变成了我们需要的打钩格式**提示：如果需要打叉，只要把2611改成2612即可**
4. 这种快捷键相信许多人都不知道，我们先按住键盘上的「ALT」键不放，然后在小键盘数字区输入「9745」，输入完成后，松开「ALT」键，就能够输入一个方框中打钩的符号。同理输入「9746」就是方框中打叉。



### 论文内容

基数估计是数据库查询优化中不可或缺的一部分，传统的基数估计方法包括采样，摘要等，随着人工智能领域的不断发展，基于学习的方法也不断地被提出，包括使用集卷积神经网络的监督学习以及自回归模型的无监督学习等



---

2023年11月14日11点06分

上午配置集群的外网连接 最后似乎需要一个vps更方便，还是使用其他方式连接linux的外网吧，还是用vmware吧

方法都快翻烂了，目前有几个难题：

1. 没有图形化界面，不方便使用clash等软件的形式
2. 纯命令行的方式，配置有点麻烦，需要自己有一台vps







2023年11月15日00点50分

知识图谱的非时序性更新

知识图谱非时序性更新的问题主要指的是，传统的知识图谱更新模式往往需要全部重新训练或更新，对于大型知识图谱，这种方式开销巨大且时间耗时。因此，如何结合图神经网络和增量更新来解决这个问题，主要可以从以下几个步骤考虑：

1.**知识图谱的分片处理**：把知识图谱根据一定规则分为多个子图，每个子图可以单独进行图神经网络的训练。这步的目标是实现图的分布式处理，将一个大问题分解为多个子问题，降低计算和内存压力。

2.**设计图神经网络模型**：根据实际问题选择或设计合适的图神经网络模型。模型需要能够接受增量更新的输入，适应动态的知识图谱结构。

3.**适应性训练策略**：设计一个适应性的训练策略，当知识图谱中的某部分数据发生变化时，只需对受影响的子图进行训练，而不是对整个知识图谱进行全局更新。对于那些没有发生变化的部分，可以直接使用之前的训练结果。这种方式可以大大节省计算资源和时间。

4.**孤立节点和新节点处理**：对于新添加的节点，或者是因为更新导致其它节点被移除而成为孤立的节点，要设计特殊的处理方式。比如可以先对新节点进行随机初始化，然后使用已训练的模型对其进行预测，以此快速获取其向量表示；对于孤立节点，可以考虑移出模型，或者利用其邻居节点信息补充。

5.**有效的更新策略**：嵌入向量的更新需要结合新的知识图谱信息和原有的嵌入，一种可能的方法是线性插值，另一种可能的方法是使用更新的加权，考虑到新旧信息的贡献。

这是一个比较复杂的问题，每一个步骤都需要深入的探索和改进。但如果能够成功，这种方式将大大提高知识图谱的实时性和准确性，对于许多领域，比如推荐系统、搜索引擎等，都有很大的应用价值。



---

2023年12月5日14点34分

### LSS（learned sketch for subgraph）论文阅读模板

| **序号** | **作者及时间** | **论文题目/研究问题**                                        | **主要结论**                               | **采用的方法/论据**                                          | **文章思路** | **期刊及等级** |
| -------- | -------------- | ------------------------------------------------------------ | ------------------------------------------ | ------------------------------------------------------------ | ------------ | -------------- |
|          | 2021           | (LSS)A Learned Sketch for Subgraph Counting                  | 一种基于ml的图查询匹配的方法               | gnn+主动学习，将一个查询图分解成多个子图，然后首先使用主动学习学习每个子结构的权重，然后计算每个子图的基数（子图同态函数），最后再求整体的基数，<br />还有一个学习器，就是用已知基数和查询训练模型，然后预测未知查询，然后使用q-error，使用一个不确定性函数来评估每个查询的预测不确定性，并对不确定性进行偏置采样。例如，我们可以选择预测误差最大的查询q1和q2，以帮助改进模型的性能。<br />接下来，我们计算选定查询的真实子图计数，并将它们添加到训练数据中，得到一个新的训练数据集Q''={(q1,c(q1)), (q2,c(q2)), (q3,c(q3)), (q4,c(q4)), (q5,c(q5))}，其中q4和q5是我们选择的查询，c(q4)和c(q5)是它们的真实子图计数。然后，我们使用这个增强的训练数据集来重新训练LSS模型，以改进其性能 |              | VLDB           |
|          | 2022           | Streaming Graph Neural Networks via Generative Replay        | 解决图神经网络的增量更新问题               | 使用gnn+生成模型，增量训练更新的节点或边，相关性比较强，会导致新旧模式的改变，这样会造成较大的误差，使用生成模型，保留历史图数据，对更改的节点前后时间节点的快照进行对比，计算所谓的差异，若是超过一定阈值，那么目前的gnn0就无法适应当前的图，若不超过，则认为gnn0是可以符合当前更新之后的图，那就不需要。 |              | KDD            |
|          | 2020           | G-CARE                                                       | 实现了一个框架可以用来评估各种子图计数方法 | 解释了各种最流行的解决子图计数的方法，包括摘要的方法，采样的方法，以及在关系型数据的一些方法 |              | sigmod         |
|          | 2022           | lmkg-s                                                       | 基于图神经网络进行模型匹配的方法           |                                                              |              | edbt           |
|          | 2023           | GNCE                                                         | 基于图嵌入和图神经网络的知识图谱基数估计   |                                                              |              | 预印           |
|          | 2023           | LKGE(Lifelong Embedding Learning and Transfer for Growing Knowledge Graphs) | 一种新的嵌入学习的方法（lifelong           | 在知识图谱的更新过程会产生一个个快照S，就是某个时刻的知识图谱的状态，每个快照定义为三元组（Ti，Ei，Ri），分别表示事实集（模式集），实体集，关系集 |              | AAAi           |



在知识图谱上做的查询通常会说是匹配查询图的模式子图，很容易和图上的子图匹配混淆，其实在知识图谱中的匹配模式子图，子图表示的是整个知识图谱的子图，这些子图匹配查询图的模式

> 在知识图谱中查找符合某个查询的过程通常涉及图模式匹配。图模式匹配是指在知识图谱中寻找与给定查询图模式相匹配的子图。这个过程可以被看作在图谱中查找与查询图模式相对应的子结构或子图。





---

## other

2023年12月7日10点18分

刚刚看了一下前向传播和反向传播的问题，说法都是前向传播其实就是准备反向传播需要的数据，反向传播就是梯度下降的具体应用

简单理解就是说，前向传播就是一次数据输入，然后得到一个预测的结果（可能是不正确的，有偏差），然后反向传播就是根据预测值和真实值的偏差，对输入的数进行修改，这个真实值通常是已知的，在模型的训练过程中进行运用的。

> 在反向传播过程中，真实结果通常是已知的。反向传播是一种用于训练神经网络的优化算法，其目的是通过调整网络参数来最小化预测结果与真实结果之间的误差。在训练过程中，我们通常会使用一个已知的数据集来训练模型，并将数据集中的每个样本的真实结果作为参考，来计算预测结果与真实结果之间的误差。
>
> 具体来说，反向传播算法会首先计算模型的预测结果，然后将预测结果与真实结果之间的误差反向传播回网络中，以计算每个参数对误差的贡献。这些参数的梯度可以用来更新参数，从而使模型的预测结果更接近真实结果。
>
> 因此，在反向传播过程中，真实结果通常是已知的，并且用于计算误差和更新参数。



---

2023年12月9日11点05分

### G-CARE



图同态：

> 给定两个图 G = (VG, EG) 和 H = (VH, EH)，一个图同态是一个映射函数*f*:*V**G*→*V**H*，满足以下条件：
>
> 1. 对于 G 中的每一条边 (u, v)，都有一条边(*f*(*u*),*f*(*v*)) 在 H 中。
> 2. 对于 G 中的每个顶点 u，都有f*(*u*) 在 H 中。
>
> 这就意味着，图同态保持了图中的邻接关系。如果两个图之间存在图同态，则我们说这两个图是同构的。



这篇文章主要介绍了几种子图匹配上的方法，分为两类，在图上的和以关系型数据上的，总体来说都是将查询图进行分解，然后单独计算，最后再聚合

Characteristic Sets (C-SET)是一种特征集的方法，

SumRDF提出了一种摘要图的方法，将数据图中节点和边进行映射，最后直接在摘要图上计算

IMPR介绍一种采样的方法，使用随机行走获得可见的数据图

然后就是几种CARDINALITY ESTIMATION TECHNIQUES FOR RELATIONAL DATA技术，没怎么看，一种Wander Join (WJ)，这种是在论文中表现最好的

图拓扑就是各种类型的查询，星型，链型，环型，树形等等



#### 数据集

查询图格式：

```bash
t # s 1
v 0 0 -1
v 1 0 -1
v 2 0 -1
e 0 1 0
e 1 2 0
```

1. **文件头:**

   - `t # s <query_id>` - 文件头以 "t" 开头，表示这是一个查询图。`<query_id>` 是一个不小于 0 的任意整数。

   例子: `t # s 0`

2. **查询顶点:**

   - 接下来的 N 行分别表示 N 个查询顶点。

   - 格式: 

     ```
     v <id> <label> <dvid>
     ```

     ，其中

     - `<id>` 是从 0 开始的查询顶点编号，
     - `<label>` 是查询顶点的标签，
     - `<dvid>` 是绑定到此查询顶点的数据顶点的数据顶点编号。

   例子:

   ```
   Copy codev 0 1 2
   v 1 3 -1
   ```

   在这个例子中，有两个查询顶点：

   - 顶点 0 的标签为 1，绑定到数据顶点 2。
   - 顶点 1 的标签为 3，未绑定到特定的数据顶点（用 -1 表示）。

3. **查询边:**

   - 接下来的 M 行表示 M 条查询边。
   - 格式: `e <id1> <id2> <label>`，表示从查询顶点 `<id1>` 到查询顶点 `<id2>` 的有向、带标签的边，标签为 `<label>`。

   例子:

   ```
   Copy code
   e 0 1 4
   ```

   在这个例子中，有一条从查询顶点 0 到查询顶点 1 的有向边，标签为 4。



数据图：

1. **文件头:**

   - `t # <graph_id>` - 文件头以 "t" 开头，表示这是一个数据图。`<graph_id>` 是一个不小于 0 的任意整数。

   例子: `t # 1`

2. **数据顶点:**

   - 接下来的 N 行分别表示 N 个数据顶点。

   - 格式: 

     ```
     v <id> <label1> <label2> …
     ```

     ，其中

     - `<id>` 是数据顶点的编号，
     - `<label1>, <label2>, …` 是数据顶点的标签集合，一个数据顶点可以有多个标签。如果没有指定标签，默认值为 0。

   例子:

   ```
   Copy codev 0 1 2
   v 1 3 4
   ```

   在这个例子中，有两个数据顶点：

   - 顶点 0 的标签为 1 和 2。
   - 顶点 1 的标签为 3 和 4。

3. **数据边:**

   - 接下来的 M 行表示 M 条数据边，格式与查询边相同。
   - 格式: `e <id1> <id2> <label>`，表示从数据顶点 `<id1>` 到数据顶点 `<id2>` 的有向、带标签的边，标签为 `<label>`。

   例子:

   ```
   Copy code
   e 0 1 5
   ```

   在这个例子中，有一条从数据顶点 0 到数据顶点 1 的有向边，标签为 5。

   ```bash
   t # 16
   v 0 0
   v 1 0
   v 2 0
   v 3 0
   v 4 0
   e 2 3 0
   e 2 1 0
   e 1 0 0
   e 2 4 0
   
   ```

查询图和数据图区别在于第一行查询图包含s符号，数据图的顶点会有很多标签

**基本图模式，一个三元组，然后and操作，和图模式的说法，基本图上的 其实就是连接**



---

2023年11月17日14点49分

### 终端走代理的方式

https://github.com/shadowsocks/shadowsocks-windows/issues/1489

前提条件，本地开了ssr，shadowsocks选项设置中查看端口号是多少

在cmd可以直接`set HTTP_PROXY=http://127.0.0.1:1080` and `set HTTPS_PROXY=http://127.0.0.1:1080`  然后直接 `curl.exe -vv www.google.com`

但是还是ping不通，通过配置代理是不能影响ping命令的。大家都知道ping命令是直接使用icmp协议来检测网址是否可达的。而我们配置的代理是直接配置了http代理。

Http是应用层协议，icmp是网络层协议。配置代理过程是配置了应用层协议，是不会影响网络层协议的，也就解释了设置http代理以后在终端还是ping不通Google。
而在powershell中要这样设置代理`$env:http_proxy = "http://localhost:1080/"` `$env:https_proxy = "http://localhost:1080/"`

虽然如上所说配置代理是没用的，直接用curl简易测试，win11自带 

`curl.exe -vv www.google.com`不用vv也行，有反应就行

![image-20231117145941370](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20231117145941370.png)



18点23分

重大消息，还是要改一下代理，没改代理cmd直接用curl超时了，改一下代理可以了，不知道是不是就那时候不行

![image-20231117182440193](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20231117182440193.png)



---

2023年11月20日14点43分

昨天做了一个任务是关于c语言改bug的题目，关于多线程的，这种改代码的实在是难搞，最主要是pthread不是很熟悉，对于使用gdb调试不懂，对于类似的改代码的还是少接好一点。

#### 

### wsl安装问题

22点03分

windows上安装wsl从Microsoft store下载ubuntu，打开报错

```bash
WslRegisterDistribution failed with error: 0x800701bc
Error: 0x800701bc WSL 2 ?????????????????? https://aka.ms/wsl2kernel

Press any key to continue...
```

查看了一下说是需要下载 适用于 x64 计算机的 WSL2 Linux 内核更新包：https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi

然后再次打开成功了
<img src="C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20231120220652003.png" alt="image-20231120220652003" style="zoom:50%;" />

下次只需要在终端中输入`bash`就可以打开wsl了，在文件夹Linux中也能看到对应的wsl



---

2023年11月21日10点17分

关于sui client

> Generated new keypair for address with scheme "secp256k1" [0xef8ed60de2540e7d1b85c84d2071d744b717430888bd7ee4eeb1d73b4875391c]
> Secret Recovery Phrase : [garlic trap build situate help peace spoil crazy install axis hover afraid]
> Client for interacting with the Sui network



**vscode上安装wsl，在wsl终端直接输入code就可以自动连接vscode，嘎嘎好使**



---

2023年11月22日16点24分

在github页面更新之后同步本地

`git pull origin add-member`



---

2023年12月24日10点47分

## 广州travel plan

#### 12月30日

13.10 - 14.00 广州南-> 万江国际公寓（到站集合时间差不多13：10）差不多12公里  打车13.30左右出发 差不多半个小时到达 **提前准备点零食，路上要花时间**

14.00 - 14.30 万江国际公寓 找好酒店入住休整 确定plan

14.40 - 15.40 附近找个地方吃饭肠粉（大众点评4星左右）

15.40 - 17.40 陈家祠（距离酒店5.1公里）

17.40 - 18.40 西华路吃吃喝喝  距离陈家祠3公里

18.40 - 20.40 永庆坊，粤剧博物馆，附近吃晚餐 距离西华路3公里

20.40 - 21.40 永庆坊附近闲逛 美食

21.40 back hotel



#### 12月31日

8.30 - 9. 起床

9.30 - 10.30 吃早茶（叹茶靓点距离1.4公里，点都德距离4公里）

10.30 - 11. 30 圣心大教堂（距离吃早茶地方3.8公里 据说没什么内容 浏览很快）

11.30 - 12.30 沙面岛（距离大教堂1.8公里 拍照打卡）

12.30 - 13. 30 吃饭饭（据有很多吃的

13.30 - 14.30 十三行博物馆  粤海关博物馆（可以不去） 沿江西路 据说风景很美（距离沙面岛700m 

14.30 - 16.30 广东省博物馆（需要提前预约 提前一周 广州大剧院 广州图书馆作为备选

16.30 - 17.30 海心沙拍照打卡广州塔 有轨电车打卡（估计人多 不坐纯拍照）（APM线海心沙站两棵椰子树可以拍广州塔全貌（距离博物馆500m

17.30 - 18.30 附近吃饭饭

18.30 - 20.30 附近闲逛（找个地方微醺

20.30 - 00.00 散步 等待跨年

00.00 走路散步回家（打不到车先逛一番



#### 1月1日

10.00 - 11.00 起床床

11.00 - 12. 00 吃早茶（再吃一番）

12.30 - 14.30 越秀公园

14.30 -15.30 中山纪念馆

15.30 - 16.30 北京路步行街吃吃喝喝

待补充。。。



#### 1月2日

8.30 - 9.00 起床床

9.30 -10. 30 吃早茶

10.30 - 12. 30 动物园

13.30 回酒店取行李 back school





---

2023年12月25日15点45分

## python项目导出包

安装pipreqs

`pip install pipreqs`

导出项目依赖包

`pipreqs . --encoding=utf8 --force`

表示使用utf8编码，--force表示如果当前目录有requirements.txt则覆盖



---

2023年12月25日17点06分

## 方法部分

终身嵌入学习(lifelong embedding learning)和图神经网络

建模为回归问题



解释什么是终身嵌入学习，是将嵌入学习作为某一层为训练还是预训练得方式，然后还有一个动态图神经网络的描述，就是对那种局部更新节点和边的那种情况的一种升级。

overview并不是具体模型或者方法的overview



画个图来表示估计过程？



知识图谱数据的更新和传统数据库的更新有本质的不同，这样才能有现实意义。



在知识图谱中进行基数估计，使用深度学习方法通常涉及到嵌入学习和深度学习模型。以下是一种典型的基于深度学习的知识图谱基数估计方法，使用图神经网络（Graph Neural Network, GNN）来学习实体和关系的表示。这里以节点（实体）基数估计为例：



用快照的说法是因为我们假设知识图谱是不断变化的 而我们得到的是知识图谱某一时刻的复制 这不代表整个知识图谱 用复制又显得低端 所以用快照

### 1. 基本符号定义：

- �*G*：知识图谱，包含实体和关系的图结构。
- �*V*：图谱中的实体集合。
- ℎ�(0)*h**v*(0)：实体 �*v* 在第 0 层的初始化表示，通常为嵌入向量。

### 2. 图神经网络表示：

#### 2.1. 聚合函数：

![image-20231226111555064](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20231226111555064.png)



ℎ�(�+1)=Agg({ℎ�(�):�∈Neighborhood(�)})*h**v*(*l*+1)=Agg({*h**u*(*l*):*u*∈Neighborhood(*v*)})

其中，ℎ�(�)*h**v*(*l*) 是节点 �*v* 在第 �*l* 层的表示，Neighborhood(�)Neighborhood(*v*) 是节点 �*v* 的邻居集合，AggAgg 是聚合函数。

#### 2.2. 更新规则：

ℎ�(�+1)=ReLU(�(�)⋅ℎ�(�)+∑�∈Neighborhood(�)�(�)⋅ℎ�(�))*h**v*(*l*+1)=ReLU(*W*(*l*)⋅*h**v*(*l*)+∑*u*∈Neighborhood(*v*)*W*(*l*)⋅*h**u*(*l*))

其中，�(�)*W*(*l*) 是权重矩阵，ReLUReLU 是修正线性单元激活函数。

### 3. 基数估计：

通过学习到的节点表示，可以使用全连接层或其他模型来进行实体基数估计。

![image-20231226111625100](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20231226111625100.png)

�^�=EstimateCount(ℎ�(�))*c*^*v*=EstimateCount(*h**v*(*L*))

其中，�*L* 是图神经网络的层数，�^�*c*^*v* 是实体 �*v* 的基数估计。

### 4. 损失函数：

使用一个损失函数来衡量估计基数与真实基数之间的差距。一种可能的损失函数是均方误差（Mean Squared Error, MSE）：

�=1∣�∣∑�∈�(�^�−��)2L=∣*V*∣1∑*v*∈*V*(*c*^*v*−*c**v*)2

其中，��*c**v* 是实体 �*v* 的真实基数。

### 5. 优化：

通过随机梯度下降（Stochastic Gradient Descent, SGD）或其他优化算法来最小化损失函数，更新网络参数。

![image-20231226111635702](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20231226111635702.png)

�=�−�∇��*θ*=*θ*−*α*∇*θ*L

其中，�*θ* 是网络参数，�*α* 是学习率。

![image-20231226111647635](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20231226111647635.png)

### 6. 训练过程：

迭代执行优化步骤，直至损失函数收敛或达到预定的训练迭代次数。

这是一个简单的框架，具体的实现会根据问题的特点进行调整。在实践中，还可能涉及到正则化、批处理等技术来提高模型的泛化性能。总体来说，这个方法通过学习知识图谱中实体的表示，从而进行基数估计，使模型能够更好地捕捉图谱中的复杂关系。



---

## word如何在第三页开始页码编号

首先在第二页页面点击布局 然后插入下一页b页  然后编号 之后在b页进行编号取消链接到上一节 这时候b页是多余的 

https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/

  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/





2024年4月28日16点34分

今天得到一个新的观点 基数估计的描述

基数估计算法是为了解决这样一个问题：设想你有一个巨大的含有重复项的数据集合，这个数据大到无法完全存储到内存中，但是你想知道这个数据集合中有多少不同的元素，这个不同元素的个数就叫基数（Cardinality）。

也是估计子查询的基数的需求



球类比赛报名表 保险情况

气排球 17 24横幅 证书 签到表 计分表 奖杯 气排球 工作人员用水

气排球 17 24 

根据预算表

羽毛球18 19 未确定名单 保险购买 安全承诺书

乒乓球25 26 报名表收集 保险

气排球 

场地 气排球 横幅

裁判 赛程表 报名表 

每个场地 一个记分员 两个边裁 一个主裁  边裁研会安排排班（周一）

积分表 证书 证书皮套

篮球

报名表 买保险 



